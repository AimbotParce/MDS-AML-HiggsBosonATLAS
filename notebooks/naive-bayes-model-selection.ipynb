{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eded411",
   "metadata": {},
   "source": [
    "## Naive Bayes Model Selection\n",
    "\n",
    "We have implemented several different variants of the Naive Bayes classifier, each with its own assumptions and characteristics. To determine which model performs best for our specific dataset, we will conduct a model selection process using some resampling technique.\n",
    "\n",
    "### Choice of Resampling Technique\n",
    "\n",
    "By default, we will use k-fold cross-validation for model selection and hyperparameter tuning. However, in some algorithms, training is extremely costly, and in such cases, because we have a large dataset, we may opt for a simple train-validation split instead. The choice of resampling technique will be made based on the computational cost of training each model.\n",
    "\n",
    "Note that in all cases, the test set will remain untouched until the final evaluation phase.\n",
    "\n",
    "### Model Space\n",
    "\n",
    "We will consider the following Naive Bayes variants for model selection:\n",
    "1. Gaussian Naive Bayes Variants:\n",
    "   1. Gaussian Naive Bayes (As a baseline model): The standard Gaussian Naive Bayes model that assumes features are normally distributed.\n",
    "      1. Dropping rows with missing values\n",
    "      2. Dropping features with missing values\n",
    "   2. Robust Gaussian Naive Bayes: A variant of the Gaussian Naive Bayes that uses the missingness of a feature as an additional categorical feature. (`laplace_smoothing in [0, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]`)\n",
    "   3. Categorical-Aware Robust Gaussian Naive Bayes with: A variant of the Robust Gaussian Naive Bayes that treats continuous features as independent of one another (as does the standard Naive Bayes model) but dependent on the categorical features (not the missingness indicators). (`laplace_smoothing in [0, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]`)\n",
    "2. Histogram-Based Naive Bayes Variants:\n",
    "   1. Histogram Naive Bayes: A Naive Bayes model that uses histograms to estimate the probability density functions of continuous features.\n",
    "      1. Dropping rows with missing values (`bins in range(10, 1000, 10) + [None]`)\n",
    "      2. Dropping features with missing values (`bins in range(10, 1000, 10) + [None]`)\n",
    "   2. Robust Histogram Naive Bayes: A variant of the Histogram Naive Bayes that incorporates missingness indicators as additional categorical features. (`bins in range(10, 1000, 10) + [None]`, `laplace_smoothing in [0, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]`)\n",
    "   3. Categorical-Aware Robust Histogram Naive Bayes: A variant of the Robust Histogram Naive Bayes that treats continuous features as independent of one another but dependent on the categorical features. (`bins in range(10, 1000, 10) + [None]`, `laplace_smoothing in [0, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]`)\n",
    "3. Kernel Density Estimation (KDE) Based Naive Bayes Variants:\n",
    "   1. Gaussian KDE Naive Bayes: A Naive Bayes model that uses Kernel Density Estimation with a Gaussian Kernel to estimate the probability density functions of continuous features.\n",
    "      1. Dropping rows with missing values (`bandwidth in [0.05, 0.1, 0.5, 1, 2, None]`, `num_points in [100, 1000, 3000, 5000]`, `range_padding in [0, 0.1, 0.5]`)\n",
    "      2. Dropping features with missing values (`bandwidth in [0.05, 0.1, 0.5, 1, 2, None]`, `num_points in [100, 1000, 3000, 5000]`, `range_padding in [0, 0.1, 0.5]`)\n",
    "   2. Robust Gaussian KDE Naive Bayes: A variant of the KDE Naive Bayes that incorporates missingness indicators as additional categorical features. (`bandwidth in [0.05, 0.1, 0.5, 1, 2, None]`, `num_points in [100, 1000, 3000, 5000]`, `range_padding in [0, 0.1, 0.5]`, `laplace_smoothing in <about_the_best_as_in_previous_models> + [0]`)\n",
    "   3. Categorical-Aware Robust Gaussian KDE Naive Bayes: A variant of the Robust KDE Naive Bayes that treats continuous features as independent of one another but dependent on the categorical features. (`bandwidth in [0.05, 0.1, 0.5, 1, 2, None]`, `num_points in [100, 1000, 3000, 5000]`, `range_padding in [0, 0.1, 0.5]`, `laplace_smoothing in <about_the_best_as_in_previous_models> + [0]`)\n",
    "   > **Note:** KDE models are by design lazily evaluated, meaning that training consists on just storing all the training data, and actual density estimation is performed at prediction time. Therefore, they are extremely costly to evaluate. For that reason, an **approximation** is used instead, where a large-enough sample of the feature axis is drawn and the density is estimated at those points only, using them to approximate the density at prediction time via 1-nearest-neighbor.\n",
    "4. Box-Cox Transformed Gaussian Naive Bayes Variants:\n",
    "   1. Box-Cox Transformed Gaussian Naive Bayes: A Naive Bayes model that applies a Box-Cox transformation to continuous features before modeling them with Gaussian distributions.\n",
    "      1. Dropping rows with missing values\n",
    "      2. Dropping features with missing values\n",
    "   2. Robust Box-Cox Transformed Gaussian Naive Bayes: A variant of the Box-Cox Transformed Gaussian Naive Bayes that incorporates missingness indicators as additional categorical features. (`laplace_smoothing in [0, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]`)\n",
    "   3. Categorical-Aware Robust Box-Cox Transformed Gaussian Naive Bayes: A variant of the Robust Box-Cox Transformed Gaussian Naive Bayes that treats continuous features as independent of one another but dependent on the categorical features. (`laplace_smoothing in [0, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]`)\n",
    "\n",
    "\n",
    "> **Note:** In all cases, categorical features are modeled using a multi-class generalization of the Bernoulli distribution ($f(x=i|\\vec{p})=p_i$), while continuous features are modeled using different Density Estimation techniques (Gaussian, KDE, or Histogram)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c0ca5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DER_mass_MMC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DER_mass_transverse_met_lep",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DER_mass_vis",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DER_pt_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DER_deltaeta_jet_jet",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DER_mass_jet_jet",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DER_prodeta_jet_jet",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DER_deltar_tau_lep",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DER_pt_tot",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DER_sum_pt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DER_pt_ratio_lep_tau",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DER_met_phi_centrality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DER_lep_eta_centrality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRI_tau_pt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRI_tau_eta",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRI_tau_phi",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRI_lep_pt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRI_lep_eta",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRI_lep_phi",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRI_met",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRI_met_phi",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRI_met_sumet",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRI_jet_num",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PRI_jet_leading_pt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRI_jet_leading_eta",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRI_jet_leading_phi",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRI_jet_subleading_pt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRI_jet_subleading_eta",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRI_jet_subleading_phi",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRI_jet_all_pt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Weight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "8dde9091-8715-4914-bcf2-e77d5bf01ecb",
       "rows": [
        [
         "0",
         "90.901",
         "85.57",
         "75.316",
         "40.945",
         null,
         null,
         null,
         "1.869",
         "3.111",
         "135.816",
         "1.073",
         "-1.06",
         null,
         "44.964",
         "-0.972",
         "0.788",
         "48.247",
         "-0.738",
         "-1.066",
         "37.976",
         "2.136",
         "185.052",
         "1",
         "42.605",
         "-1.962",
         "-2.519",
         null,
         null,
         null,
         "42.605",
         "0.58939479024",
         "b"
        ],
        [
         "1",
         "133.477",
         "3.669",
         "99.223",
         "227.121",
         "2.243",
         "365.016",
         "2.278",
         "1.223",
         "3.539",
         "440.917",
         "2.495",
         "0.949",
         "0.094",
         "51.602",
         "-0.978",
         "0.509",
         "128.748",
         "-0.155",
         "-0.395",
         "63.331",
         "-0.436",
         "453.808",
         "2",
         "173.249",
         "-0.759",
         "2.545",
         "87.317",
         "-3.002",
         "-2.594",
         "260.566",
         "0.000461281573949",
         "s"
        ],
        [
         "2",
         "115.111",
         "26.919",
         "77.658",
         "50.266",
         null,
         null,
         null,
         "2.691",
         "3.655",
         "133.495",
         "1.398",
         "1.398",
         null,
         "33.191",
         "-0.614",
         "-1.834",
         "46.409",
         "-0.248",
         "1.783",
         "27.559",
         "2.555",
         "176.401",
         "1",
         "53.895",
         "0.685",
         "-0.613",
         null,
         null,
         null,
         "53.895",
         "0.623626505663",
         "b"
        ],
        [
         "3",
         null,
         "83.642",
         "74.642",
         "25.176",
         null,
         null,
         null,
         "2.646",
         "25.176",
         "53.813",
         "1.393",
         "-1.361",
         null,
         "22.488",
         "0.205",
         "-1.051",
         "31.326",
         "2.215",
         "0.671",
         "60.143",
         "-3.012",
         "77.408",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         "0.0",
         "1.77211428467",
         "b"
        ],
        [
         "4",
         "81.958",
         "7.074",
         "46.894",
         "90.979",
         "0.952",
         "83.883",
         "-0.226",
         "1.626",
         "17.517",
         "174.686",
         "1.05",
         "1.171",
         "0.001",
         "29.799",
         "0.486",
         "2.777",
         "31.299",
         "1.271",
         "1.353",
         "47.727",
         "1.536",
         "265.013",
         "2",
         "80.028",
         "-0.456",
         "-1.902",
         "33.561",
         "0.496",
         "-0.555",
         "113.589",
         "0.418760425129",
         "b"
        ]
       ],
       "shape": {
        "columns": 32,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.901</td>\n",
       "      <td>85.570</td>\n",
       "      <td>75.316</td>\n",
       "      <td>40.945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.869</td>\n",
       "      <td>3.111</td>\n",
       "      <td>135.816</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>42.605</td>\n",
       "      <td>-1.962</td>\n",
       "      <td>-2.519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.605</td>\n",
       "      <td>0.589395</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>133.477</td>\n",
       "      <td>3.669</td>\n",
       "      <td>99.223</td>\n",
       "      <td>227.121</td>\n",
       "      <td>2.243</td>\n",
       "      <td>365.016</td>\n",
       "      <td>2.278</td>\n",
       "      <td>1.223</td>\n",
       "      <td>3.539</td>\n",
       "      <td>440.917</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>173.249</td>\n",
       "      <td>-0.759</td>\n",
       "      <td>2.545</td>\n",
       "      <td>87.317</td>\n",
       "      <td>-3.002</td>\n",
       "      <td>-2.594</td>\n",
       "      <td>260.566</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115.111</td>\n",
       "      <td>26.919</td>\n",
       "      <td>77.658</td>\n",
       "      <td>50.266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.691</td>\n",
       "      <td>3.655</td>\n",
       "      <td>133.495</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>53.895</td>\n",
       "      <td>0.685</td>\n",
       "      <td>-0.613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.895</td>\n",
       "      <td>0.623627</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>83.642</td>\n",
       "      <td>74.642</td>\n",
       "      <td>25.176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.646</td>\n",
       "      <td>25.176</td>\n",
       "      <td>53.813</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.772114</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.958</td>\n",
       "      <td>7.074</td>\n",
       "      <td>46.894</td>\n",
       "      <td>90.979</td>\n",
       "      <td>0.952</td>\n",
       "      <td>83.883</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>1.626</td>\n",
       "      <td>17.517</td>\n",
       "      <td>174.686</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80.028</td>\n",
       "      <td>-0.456</td>\n",
       "      <td>-1.902</td>\n",
       "      <td>33.561</td>\n",
       "      <td>0.496</td>\n",
       "      <td>-0.555</td>\n",
       "      <td>113.589</td>\n",
       "      <td>0.418760</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n",
       "0        90.901                       85.570        75.316    40.945   \n",
       "1       133.477                        3.669        99.223   227.121   \n",
       "2       115.111                       26.919        77.658    50.266   \n",
       "3           NaN                       83.642        74.642    25.176   \n",
       "4        81.958                        7.074        46.894    90.979   \n",
       "\n",
       "   DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "0                   NaN               NaN                  NaN   \n",
       "1                 2.243           365.016                2.278   \n",
       "2                   NaN               NaN                  NaN   \n",
       "3                   NaN               NaN                  NaN   \n",
       "4                 0.952            83.883               -0.226   \n",
       "\n",
       "   DER_deltar_tau_lep  DER_pt_tot  DER_sum_pt  ...  PRI_jet_num  \\\n",
       "0               1.869       3.111     135.816  ...            1   \n",
       "1               1.223       3.539     440.917  ...            2   \n",
       "2               2.691       3.655     133.495  ...            1   \n",
       "3               2.646      25.176      53.813  ...            0   \n",
       "4               1.626      17.517     174.686  ...            2   \n",
       "\n",
       "   PRI_jet_leading_pt  PRI_jet_leading_eta  PRI_jet_leading_phi  \\\n",
       "0              42.605               -1.962               -2.519   \n",
       "1             173.249               -0.759                2.545   \n",
       "2              53.895                0.685               -0.613   \n",
       "3                 NaN                  NaN                  NaN   \n",
       "4              80.028               -0.456               -1.902   \n",
       "\n",
       "   PRI_jet_subleading_pt  PRI_jet_subleading_eta  PRI_jet_subleading_phi  \\\n",
       "0                    NaN                     NaN                     NaN   \n",
       "1                 87.317                  -3.002                  -2.594   \n",
       "2                    NaN                     NaN                     NaN   \n",
       "3                    NaN                     NaN                     NaN   \n",
       "4                 33.561                   0.496                  -0.555   \n",
       "\n",
       "   PRI_jet_all_pt    Weight  Label  \n",
       "0          42.605  0.589395      b  \n",
       "1         260.566  0.000461      s  \n",
       "2          53.895  0.623627      b  \n",
       "3           0.000  1.772114      b  \n",
       "4         113.589  0.418760      b  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data and prepare the clean variables.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/train_no_preprocess.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9ca716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Label\", \"Weight\"])\n",
    "y = df[\"Label\"]\n",
    "weights = df[\"Weight\"]\n",
    "categorical_features = df.columns.get_indexer([\"PRI_jet_num\"]).tolist()\n",
    "\n",
    "df_drop_rows = df[~X.isna().any(axis=1)].reset_index(drop=True)\n",
    "X_drop_rows = df_drop_rows.drop(columns=[\"Label\", \"Weight\"])\n",
    "y_drop_rows = df_drop_rows[\"Label\"]\n",
    "weights_drop_rows = df_drop_rows[\"Weight\"]\n",
    "categorical_features_drop_rows = df_drop_rows.columns.get_indexer([\"PRI_jet_num\"]).tolist()\n",
    "\n",
    "df_drop_cols = df.drop(columns=X.columns[X.isna().any(axis=0)])\n",
    "X_drop_cols = df_drop_cols.drop(columns=[\"Label\", \"Weight\"])\n",
    "y_drop_cols = df_drop_cols[\"Label\"]\n",
    "weights_drop_cols = df_drop_cols[\"Weight\"]\n",
    "categorical_features_drop_cols = df_drop_cols.columns.get_indexer([\"PRI_jet_num\"]).tolist()\n",
    "\n",
    "# Convert them to numpy and store them in a datasets dictionary for easy reference.\n",
    "datasets = {\n",
    "    \"original\": (X.to_numpy(), y.to_numpy(), weights.to_numpy(), categorical_features),\n",
    "    \"drop-rows\": (\n",
    "        X_drop_rows.to_numpy(),\n",
    "        y_drop_rows.to_numpy(),\n",
    "        weights_drop_rows.to_numpy(),\n",
    "        categorical_features_drop_rows,\n",
    "    ),\n",
    "    \"drop-columns\": (\n",
    "        X_drop_cols.to_numpy(),\n",
    "        y_drop_cols.to_numpy(),\n",
    "        weights_drop_cols.to_numpy(),\n",
    "        categorical_features_drop_cols,\n",
    "    ),\n",
    "}\n",
    "del (\n",
    "    df,\n",
    "    X,\n",
    "    y,\n",
    "    df_drop_rows,\n",
    "    X_drop_rows,\n",
    "    y_drop_rows,\n",
    "    df_drop_cols,\n",
    "    X_drop_cols,\n",
    "    y_drop_cols,\n",
    "    categorical_features,\n",
    "    categorical_features_drop_rows,\n",
    "    categorical_features_drop_cols,\n",
    ")  # Free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d730a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, TypedDict, Literal, NewType, Union\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Experiment(BaseModel):\n",
    "    model_class: Literal[\"BespokeNB\", \"CategoricalAwareBespokeNB\"]\n",
    "    categorical_estimator_class: Literal[\"CategoricalEstimator\", \"RobustCategoricalEstimator\"]\n",
    "    continuous_estimator_class: Literal[\n",
    "        \"GaussianEstimator\",\n",
    "        \"RobustGaussianEstimator\",\n",
    "        \"HistogramEstimator\",\n",
    "        \"RobustHistogramEstimator\",\n",
    "        \"EagerGaussianKDEstimator\",\n",
    "        \"RobustEagerGaussianKDEstimator\",\n",
    "        \"BoxCoxGaussianEstimator\",\n",
    "        \"RobustBoxCoxGaussianEstimator\",\n",
    "    ]\n",
    "    dataset: Literal[\"original\", \"drop-rows\", \"drop-columns\"]\n",
    "    num_folds: int\n",
    "    categorical_estimator_params: Dict[str, Union[Optional[float], Optional[int]]] = {}\n",
    "    continuous_estimator_params: Dict[str, Union[Optional[float], Optional[int]]] = {}\n",
    "\n",
    "\n",
    "class ExperimentResult(Experiment):\n",
    "    fold_index: int\n",
    "    accuracy: float\n",
    "    b_recall: float\n",
    "    b_precision: float\n",
    "    b_f1_score: float\n",
    "    s_recall: float\n",
    "    s_precision: float\n",
    "    s_f1_score: float\n",
    "    ams_score: float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5730dfae",
   "metadata": {},
   "source": [
    "Let's setup the experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2edbcd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments: List[Experiment] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da48719d",
   "metadata": {},
   "source": [
    "#### Gaussian experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38d78908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes Variants:\n",
    "\n",
    "# Standard\n",
    "for dataset in [\"drop-rows\", \"drop-columns\"]:\n",
    "    experiments.append(\n",
    "        Experiment(\n",
    "            model_class=\"BespokeNB\",\n",
    "            categorical_estimator_class=\"CategoricalEstimator\",\n",
    "            continuous_estimator_class=\"GaussianEstimator\",\n",
    "            dataset=dataset,\n",
    "            num_folds=10,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Robust and categorical-aware\n",
    "for laplace_smoothing in [0, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "    experiments.append(\n",
    "        Experiment(\n",
    "            model_class=\"BespokeNB\",\n",
    "            categorical_estimator_class=\"RobustCategoricalEstimator\",\n",
    "            continuous_estimator_class=\"RobustGaussianEstimator\",\n",
    "            dataset=dataset,\n",
    "            num_folds=10,\n",
    "            continuous_estimator_params=dict(laplace_smoothing=laplace_smoothing),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    experiments.append(\n",
    "        Experiment(\n",
    "            model_class=\"CategoricalAwareBespokeNB\",\n",
    "            categorical_estimator_class=\"RobustCategoricalEstimator\",\n",
    "            continuous_estimator_class=\"RobustGaussianEstimator\",\n",
    "            dataset=dataset,\n",
    "            num_folds=10,\n",
    "            continuous_estimator_params=dict(laplace_smoothing=laplace_smoothing),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49789e2c",
   "metadata": {},
   "source": [
    "#### Histogram experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bda74ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram Naive Bayes Variants:\n",
    "\n",
    "# Standard\n",
    "for dataset in [\"drop-rows\", \"drop-columns\"]:\n",
    "    for bins in list(range(10, 1000, 10)) + [None]:\n",
    "        experiments.append(\n",
    "            Experiment(\n",
    "                model_class=\"BespokeNB\",\n",
    "                categorical_estimator_class=\"CategoricalEstimator\",\n",
    "                continuous_estimator_class=\"HistogramEstimator\",\n",
    "                dataset=dataset,\n",
    "                num_folds=10,\n",
    "                continuous_estimator_params=dict(bins=bins),\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Robust and categorical-aware\n",
    "for laplace_smoothing in [0, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "    for bins in list(range(10, 1000, 10)) + [None]:\n",
    "        experiments.append(\n",
    "            Experiment(\n",
    "                model_class=\"BespokeNB\",\n",
    "                categorical_estimator_class=\"RobustCategoricalEstimator\",\n",
    "                continuous_estimator_class=\"RobustHistogramEstimator\",\n",
    "                dataset=dataset,\n",
    "                num_folds=10,\n",
    "                continuous_estimator_params=dict(laplace_smoothing=laplace_smoothing, bins=bins),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        experiments.append(\n",
    "            Experiment(\n",
    "                model_class=\"CategoricalAwareBespokeNB\",\n",
    "                categorical_estimator_class=\"RobustCategoricalEstimator\",\n",
    "                continuous_estimator_class=\"RobustHistogramEstimator\",\n",
    "                dataset=dataset,\n",
    "                num_folds=10,\n",
    "                continuous_estimator_params=dict(laplace_smoothing=laplace_smoothing, bins=bins),\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e632ae49",
   "metadata": {},
   "source": [
    "Let us skip the KDE estimators, as they are much much more computationally expensive to run, and perform first the Box-Cox experiments.\n",
    "\n",
    "#### Box-Cox experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3bd5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-Cox Gaussian Naive Bayes Variants:\n",
    "\n",
    "# Standard\n",
    "for dataset in [\"drop-rows\", \"drop-columns\"]:\n",
    "    experiments.append(\n",
    "        Experiment(\n",
    "            model_class=\"BespokeNB\",\n",
    "            categorical_estimator_class=\"CategoricalEstimator\",\n",
    "            continuous_estimator_class=\"BoxCoxGaussianEstimator\",\n",
    "            dataset=dataset,\n",
    "            num_folds=10,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Robust and categorical-aware\n",
    "for laplace_smoothing in [0, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "    experiments.append(\n",
    "        Experiment(\n",
    "            model_class=\"BespokeNB\",\n",
    "            categorical_estimator_class=\"RobustCategoricalEstimator\",\n",
    "            continuous_estimator_class=\"RobustBoxCoxGaussianEstimator\",\n",
    "            dataset=dataset,\n",
    "            num_folds=10,\n",
    "            continuous_estimator_params=dict(laplace_smoothing=laplace_smoothing),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    experiments.append(\n",
    "        Experiment(\n",
    "            model_class=\"CategoricalAwareBespokeNB\",\n",
    "            categorical_estimator_class=\"RobustCategoricalEstimator\",\n",
    "            continuous_estimator_class=\"RobustBoxCoxGaussianEstimator\",\n",
    "            dataset=dataset,\n",
    "            num_folds=10,\n",
    "            continuous_estimator_params=dict(laplace_smoothing=laplace_smoothing),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb445fa",
   "metadata": {},
   "source": [
    "Now let's create an experiment runner function to run all the experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "143bf5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from typing import Type\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "import src.naive_bayes\n",
    "import src.evaluate\n",
    "\n",
    "\n",
    "def _instantiate_estimator(\n",
    "    estimator_cls: Type[src.naive_bayes.ProbabilityEstimator],\n",
    "    estimator_params: Dict[str, Union[Optional[float], Optional[int]]],\n",
    ") -> src.naive_bayes.ProbabilityEstimator:\n",
    "    init_kwargs = {}\n",
    "    for key in estimator_cls.__init__.__code__.co_varnames[1:]:\n",
    "        if not key in estimator_params:\n",
    "            raise ValueError(f\"Missing value for estimator parameter: {key}\")\n",
    "        init_kwargs[key] = estimator_params[key]\n",
    "    return estimator_cls(**init_kwargs)\n",
    "\n",
    "\n",
    "def _get_estimator_instances(\n",
    "    experiment: Experiment, num_features: int, categorical_features: list[int]\n",
    ") -> Dict[int, src.naive_bayes.ProbabilityEstimator]:\n",
    "    categorical_estimator_cls = getattr(src.naive_bayes, experiment.categorical_estimator_class)\n",
    "    continuous_estimator_cls = getattr(src.naive_bayes, experiment.continuous_estimator_class)\n",
    "    instances = {}\n",
    "    for feature in range(num_features):\n",
    "        if feature in categorical_features:\n",
    "            instances[feature] = _instantiate_estimator(\n",
    "                categorical_estimator_cls, experiment.categorical_estimator_params\n",
    "            )\n",
    "        else:\n",
    "            instances[feature] = _instantiate_estimator(\n",
    "                continuous_estimator_cls, experiment.continuous_estimator_params\n",
    "            )\n",
    "    return instances\n",
    "\n",
    "\n",
    "def _get_model_instance(\n",
    "    experiment: Experiment, num_features: int, categorical_features: list[int]\n",
    ") -> src.naive_bayes.BespokeNB | src.naive_bayes.CategoricalAwareBespokeNB:\n",
    "    model_cls = getattr(src.naive_bayes, experiment.model_class)\n",
    "    estimators = _get_estimator_instances(\n",
    "        experiment, num_features=num_features, categorical_features=categorical_features\n",
    "    )\n",
    "    if model_cls == src.naive_bayes.BespokeNB:\n",
    "        return model_cls(estimators=estimators)\n",
    "    elif model_cls == src.naive_bayes.CategoricalAwareBespokeNB:\n",
    "        return model_cls(\n",
    "            estimators=estimators,\n",
    "            categorical_features=categorical_features,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model class: {experiment.model_class}\")\n",
    "\n",
    "\n",
    "def run_cv_experiments(experiment: Experiment) -> List[ExperimentResult]:\n",
    "    X, y, weights, categorical_features = datasets[experiment.dataset]\n",
    "\n",
    "    # Create cross-validation folds\n",
    "    results = []\n",
    "    kf = KFold(n_splits=experiment.num_folds, shuffle=False)\n",
    "    for fold_index, (train, test) in enumerate(kf.split(X)):\n",
    "        model = _get_model_instance(experiment, num_features=X.shape[1], categorical_features=categorical_features)\n",
    "        model.fit(X[train], y[train])\n",
    "        y_pred = model.predict(X[test])\n",
    "        accuracy = accuracy_score(y[test], y_pred)\n",
    "        (b_precision, s_precision), (b_recall, s_recall), (b_f1_score, s_f1_score), _ = precision_recall_fscore_support(\n",
    "            y[test], y_pred, labels=[\"b\", \"s\"], average=None, zero_division=0\n",
    "        )\n",
    "        ams_score = src.evaluate.ams_score(y_true=y[test], y_pred=y_pred, weights=weights[test])\n",
    "        result = ExperimentResult(\n",
    "            **experiment.model_dump(),\n",
    "            fold_index=fold_index,\n",
    "            accuracy=accuracy,\n",
    "            b_recall=b_recall,\n",
    "            b_precision=b_precision,\n",
    "            b_f1_score=b_f1_score,\n",
    "            s_recall=s_recall,\n",
    "            s_precision=s_precision,\n",
    "            s_f1_score=s_f1_score,\n",
    "            ams_score=ams_score,\n",
    "        )\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefafeb8",
   "metadata": {},
   "source": [
    "And finally, let's run the experiments and collect the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95b9983a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  99%|█████████▉| 2223/2244 [3:28:18<01:40,  4.81s/it, BespokeNB with BoxCoxGaussianEstimator on drop-rows]                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  99%|█████████▉| 2224/2244 [3:28:24<01:42,  5.14s/it, BespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  99%|█████████▉| 2225/2244 [3:28:30<01:42,  5.37s/it, BespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  99%|█████████▉| 2226/2244 [3:28:33<01:25,  4.72s/it, BespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  99%|█████████▉| 2227/2244 [3:28:39<01:26,  5.07s/it, BespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  99%|█████████▉| 2228/2244 [3:28:42<01:11,  4.49s/it, BespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  99%|█████████▉| 2229/2244 [3:28:48<01:13,  4.93s/it, BespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  99%|█████████▉| 2230/2244 [3:28:51<01:01,  4.41s/it, CategoricalAwareBespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  99%|█████████▉| 2231/2244 [3:28:57<01:02,  4.84s/it, BespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  99%|█████████▉| 2232/2244 [3:29:01<00:52,  4.35s/it, BespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments: 100%|█████████▉| 2233/2244 [3:29:06<00:52,  4.81s/it, BespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments: 100%|█████████▉| 2234/2244 [3:29:10<00:43,  4.33s/it, BespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments: 100%|█████████▉| 2235/2244 [3:29:15<00:43,  4.79s/it, BespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments: 100%|█████████▉| 2236/2244 [3:29:19<00:34,  4.30s/it, CategoricalAwareBespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments: 100%|█████████▉| 2237/2244 [3:29:25<00:33,  4.80s/it, BespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments: 100%|█████████▉| 2238/2244 [3:29:28<00:25,  4.31s/it, CategoricalAwareBespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments: 100%|█████████▉| 2239/2244 [3:29:34<00:23,  4.80s/it, BespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments: 100%|█████████▉| 2240/2244 [3:29:37<00:17,  4.30s/it, CategoricalAwareBespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments: 100%|█████████▉| 2241/2244 [3:29:43<00:14,  4.78s/it, BespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments: 100%|█████████▉| 2242/2244 [3:29:46<00:08,  4.30s/it, CategoricalAwareBespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments: 100%|█████████▉| 2243/2244 [3:29:52<00:04,  4.79s/it, BespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments: 100%|██████████| 2244/2244 [3:29:55<00:00,  4.30s/it, CategoricalAwareBespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment failed: Data must be positive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments: 100%|██████████| 2244/2244 [3:29:55<00:00,  5.61s/it, CategoricalAwareBespokeNB with RobustBoxCoxGaussianEstimator on drop-columns]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "np.seterr(divide=\"ignore\", invalid=\"ignore\")\n",
    "\n",
    "experiment_results: List[ExperimentResult] = []\n",
    "failed_experiments: List[Experiment] = []\n",
    "with warnings.catch_warnings():\n",
    "    bar = tqdm(total=len(experiments), desc=\"Running experiments\")\n",
    "    for experiment in experiments:\n",
    "        bar.set_postfix_str(\n",
    "            f\"{experiment.model_class} with {experiment.continuous_estimator_class} on {experiment.dataset}\"\n",
    "        )\n",
    "        bar.refresh()\n",
    "        try:\n",
    "            experiment_results.extend(run_cv_experiments(experiment))\n",
    "        except Exception as e:\n",
    "            print(f\"Experiment failed: {e}\")\n",
    "            failed_experiments.append(experiment)\n",
    "        bar.update(1)\n",
    "        # Save intermediate results\n",
    "        df_results = pd.DataFrame([result.model_dump() for result in experiment_results])\n",
    "        df_results.to_csv(\"../results/naive_bayes_model_selection_results_intermediate.csv\", index=False)\n",
    "        failed_results = pd.DataFrame([exp.model_dump() for exp in failed_experiments])\n",
    "        failed_results.to_csv(\"../results/naive_bayes_model_selection_failed_experiments_intermediate.csv\", index=False)\n",
    "    bar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "higgsbosonatlas (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
