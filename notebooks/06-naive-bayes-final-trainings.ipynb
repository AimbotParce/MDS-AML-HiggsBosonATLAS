{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3801ac6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categorical_features_drop_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 98\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Convert them to numpy and store them in a datasets dictionary for easy reference.\u001b[39;00m\n\u001b[32m     46\u001b[39m datasets = {\n\u001b[32m     47\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moriginal\u001b[39m\u001b[33m\"\u001b[39m: (\n\u001b[32m     48\u001b[39m         X_train.to_numpy(),\n\u001b[32m   (...)\u001b[39m\u001b[32m     73\u001b[39m     ),\n\u001b[32m     74\u001b[39m }\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m (\n\u001b[32m     76\u001b[39m     df_train,\n\u001b[32m     77\u001b[39m     X_train,\n\u001b[32m     78\u001b[39m     y_train,\n\u001b[32m     79\u001b[39m     df_train_drop_rows,\n\u001b[32m     80\u001b[39m     X_train_drop_rows,\n\u001b[32m     81\u001b[39m     y_train_drop_rows,\n\u001b[32m     82\u001b[39m     df_train_drop_cols,\n\u001b[32m     83\u001b[39m     X_train_drop_cols,\n\u001b[32m     84\u001b[39m     y_train_drop_cols,\n\u001b[32m     85\u001b[39m     categorical_features,\n\u001b[32m     86\u001b[39m     categorical_features_drop_rows,\n\u001b[32m     87\u001b[39m     categorical_features_drop_cols,\n\u001b[32m     88\u001b[39m     df_test,\n\u001b[32m     89\u001b[39m     X_test,\n\u001b[32m     90\u001b[39m     y_test,\n\u001b[32m     91\u001b[39m     df_test_drop_rows,\n\u001b[32m     92\u001b[39m     X_test_drop_rows,\n\u001b[32m     93\u001b[39m     y_test_drop_rows,\n\u001b[32m     94\u001b[39m     df_test_drop_cols,\n\u001b[32m     95\u001b[39m     X_test_drop_cols,\n\u001b[32m     96\u001b[39m     y_test_drop_cols,\n\u001b[32m     97\u001b[39m     weights_test_drop_cols,\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     \u001b[43mcategorical_features_drop_cols\u001b[49m,\n\u001b[32m     99\u001b[39m )  \u001b[38;5;66;03m# Free memory\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'categorical_features_drop_cols' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the data and prepare the clean variables.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv(\"../data/processed/train_no_preprocess.csv\")\n",
    "\n",
    "X_train = df_train.drop(columns=[\"Label\", \"Weight\"])\n",
    "y_train = df_train[\"Label\"]\n",
    "weights_train = df_train[\"Weight\"]\n",
    "categorical_features = df_train.columns.get_indexer([\"PRI_jet_num\"]).tolist()\n",
    "\n",
    "df_train_drop_rows = df_train[~X_train.isna().any(axis=1)].reset_index(drop=True)\n",
    "X_train_drop_rows = df_train_drop_rows.drop(columns=[\"Label\", \"Weight\"])\n",
    "y_train_drop_rows = df_train_drop_rows[\"Label\"]\n",
    "weights_train_drop_rows = df_train_drop_rows[\"Weight\"]\n",
    "categorical_features_drop_rows = df_train_drop_rows.columns.get_indexer([\"PRI_jet_num\"]).tolist()\n",
    "\n",
    "cols_dropped = X_train.columns[X_train.isna().any(axis=0)]\n",
    "df_train_drop_cols = df_train.drop(columns=cols_dropped)\n",
    "X_train_drop_cols = df_train_drop_cols.drop(columns=[\"Label\", \"Weight\"])\n",
    "y_train_drop_cols = df_train_drop_cols[\"Label\"]\n",
    "weights_train_drop_cols = df_train_drop_cols[\"Weight\"]\n",
    "categorical_features_drop_cols = df_train_drop_cols.columns.get_indexer([\"PRI_jet_num\"]).tolist()\n",
    "\n",
    "\n",
    "df_test = pd.read_csv(\"../data/processed/test_no_preprocess.csv\")\n",
    "\n",
    "X_test = df_test.drop(columns=[\"Label\", \"Weight\"])\n",
    "y_test = df_test[\"Label\"]\n",
    "weights_test = df_test[\"Weight\"]\n",
    "categorical_features = df_test.columns.get_indexer([\"PRI_jet_num\"]).tolist()\n",
    "\n",
    "df_test_drop_rows = df_test[~X_test.isna().any(axis=1)].reset_index(drop=True)\n",
    "X_test_drop_rows = df_test_drop_rows.drop(columns=[\"Label\", \"Weight\"])\n",
    "y_test_drop_rows = df_test_drop_rows[\"Label\"]\n",
    "weights_test_drop_rows = df_test_drop_rows[\"Weight\"]\n",
    "categorical_features_drop_rows = df_test_drop_rows.columns.get_indexer([\"PRI_jet_num\"]).tolist()\n",
    "\n",
    "df_test_drop_cols = df_test.drop(columns=cols_dropped)\n",
    "X_test_drop_cols = df_test_drop_cols.drop(columns=[\"Label\", \"Weight\"])\n",
    "y_test_drop_cols = df_test_drop_cols[\"Label\"]\n",
    "weights_test_drop_cols = df_test_drop_cols[\"Weight\"]\n",
    "categorical_features_drop_cols = df_test_drop_cols.columns.get_indexer([\"PRI_jet_num\"]).tolist()\n",
    "\n",
    "# Convert them to numpy and store them in a datasets dictionary for easy reference.\n",
    "datasets = {\n",
    "    \"original\": (\n",
    "        X_train.to_numpy(),\n",
    "        y_train.to_numpy(),\n",
    "        weights_train.to_numpy(),\n",
    "        X_test.to_numpy(),\n",
    "        y_test.to_numpy(),\n",
    "        weights_test.to_numpy(),\n",
    "        categorical_features,\n",
    "    ),\n",
    "    \"drop-rows\": (\n",
    "        X_train_drop_rows.to_numpy(),\n",
    "        y_train_drop_rows.to_numpy(),\n",
    "        weights_train_drop_rows.to_numpy(),\n",
    "        X_test_drop_rows.to_numpy(),\n",
    "        y_test_drop_rows.to_numpy(),\n",
    "        weights_test_drop_rows.to_numpy(),\n",
    "        categorical_features_drop_rows,\n",
    "    ),\n",
    "    \"drop-columns\": (\n",
    "        X_train_drop_cols.to_numpy(),\n",
    "        y_train_drop_cols.to_numpy(),\n",
    "        weights_train_drop_cols.to_numpy(),\n",
    "        X_test_drop_cols.to_numpy(),\n",
    "        y_test_drop_cols.to_numpy(),\n",
    "        weights_test_drop_cols.to_numpy(),\n",
    "        categorical_features_drop_cols,\n",
    "    ),\n",
    "}\n",
    "del (\n",
    "    df_train,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    df_train_drop_rows,\n",
    "    X_train_drop_rows,\n",
    "    y_train_drop_rows,\n",
    "    df_train_drop_cols,\n",
    "    X_train_drop_cols,\n",
    "    y_train_drop_cols,\n",
    "    categorical_features,\n",
    "    categorical_features_drop_rows,\n",
    "    categorical_features_drop_cols,\n",
    "    df_test,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    df_test_drop_rows,\n",
    "    X_test_drop_rows,\n",
    "    y_test_drop_rows,\n",
    "    df_test_drop_cols,\n",
    "    X_test_drop_cols,\n",
    "    y_test_drop_cols,\n",
    "    weights_test_drop_cols,\n",
    "    categorical_features_drop_cols,\n",
    ")  # Free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5936819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Literal, Union\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class FinalExperiment(BaseModel):\n",
    "    model_class: Literal[\"BespokeNB\", \"CategoricalAwareBespokeNB\"]\n",
    "    categorical_estimator_class: Literal[\"CategoricalEstimator\", \"RobustCategoricalEstimator\"]\n",
    "    continuous_estimator_class: Literal[\n",
    "        \"GaussianEstimator\",\n",
    "        \"RobustGaussianEstimator\",\n",
    "        \"HistogramEstimator\",\n",
    "        \"RobustHistogramEstimator\",\n",
    "        \"EagerGaussianKDEstimator\",\n",
    "        \"RobustEagerGaussianKDEstimator\",\n",
    "        \"YeoJohnsonGaussianEstimator\",\n",
    "        \"RobustYeoJohnsonGaussianEstimator\",\n",
    "    ]\n",
    "    dataset: Literal[\"original\", \"drop-rows\", \"drop-columns\"]\n",
    "    categorical_estimator_params: Dict[str, Union[Optional[float], Optional[int]]] = {}\n",
    "    continuous_estimator_params: Dict[str, Union[Optional[float], Optional[int]]] = {}\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(\n",
    "            (\n",
    "                self.model_class,\n",
    "                self.categorical_estimator_class,\n",
    "                self.continuous_estimator_class,\n",
    "                frozenset(self.categorical_estimator_params.items()),\n",
    "                frozenset(self.continuous_estimator_params.items()),\n",
    "                self.dataset,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, FinalExperiment):\n",
    "            return NotImplemented\n",
    "        return (\n",
    "            self.model_class == other.model_class\n",
    "            and self.categorical_estimator_class == other.categorical_estimator_class\n",
    "            and self.continuous_estimator_class == other.continuous_estimator_class\n",
    "            and self.categorical_estimator_params == other.categorical_estimator_params\n",
    "            and self.continuous_estimator_params == other.continuous_estimator_params\n",
    "            and self.dataset == other.dataset\n",
    "        )\n",
    "\n",
    "\n",
    "class FinalExperimentResult(FinalExperiment):\n",
    "    accuracy: float\n",
    "    b_recall: float\n",
    "    b_precision: float\n",
    "    b_f1_score: float\n",
    "    s_recall: float\n",
    "    s_precision: float\n",
    "    s_f1_score: float\n",
    "    ams_score: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cccc668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from typing import Type\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "import src.naive_bayes\n",
    "import src.evaluate\n",
    "\n",
    "\n",
    "def _instantiate_estimator(\n",
    "    estimator_cls: Type[src.naive_bayes.ProbabilityEstimator],\n",
    "    estimator_params: Dict[str, Union[Optional[float], Optional[int]]],\n",
    ") -> src.naive_bayes.ProbabilityEstimator:\n",
    "    init_kwargs = {}\n",
    "    for key in estimator_cls.__init__.__code__.co_varnames[1:]:\n",
    "        if not key in estimator_params:\n",
    "            raise ValueError(f\"Missing value for estimator parameter: {key}\")\n",
    "        init_kwargs[key] = estimator_params[key]\n",
    "    return estimator_cls(**init_kwargs)\n",
    "\n",
    "\n",
    "def _get_estimator_instances(\n",
    "    experiment: FinalExperiment, num_features: int, categorical_features: list[int]\n",
    ") -> Dict[int, src.naive_bayes.ProbabilityEstimator]:\n",
    "    categorical_estimator_cls = getattr(src.naive_bayes, experiment.categorical_estimator_class)\n",
    "    continuous_estimator_cls = getattr(src.naive_bayes, experiment.continuous_estimator_class)\n",
    "    instances = {}\n",
    "    for feature in range(num_features):\n",
    "        if feature in categorical_features:\n",
    "            instances[feature] = _instantiate_estimator(\n",
    "                categorical_estimator_cls, experiment.categorical_estimator_params\n",
    "            )\n",
    "        else:\n",
    "            instances[feature] = _instantiate_estimator(\n",
    "                continuous_estimator_cls, experiment.continuous_estimator_params\n",
    "            )\n",
    "    return instances\n",
    "\n",
    "\n",
    "def _get_model_instance(\n",
    "    experiment: FinalExperiment, num_features: int, categorical_features: list[int]\n",
    ") -> src.naive_bayes.BespokeNB | src.naive_bayes.CategoricalAwareBespokeNB:\n",
    "    model_cls = getattr(src.naive_bayes, experiment.model_class)\n",
    "    estimators = _get_estimator_instances(\n",
    "        experiment, num_features=num_features, categorical_features=categorical_features\n",
    "    )\n",
    "    if model_cls == src.naive_bayes.BespokeNB:\n",
    "        return model_cls(estimators=estimators)\n",
    "    elif model_cls == src.naive_bayes.CategoricalAwareBespokeNB:\n",
    "        return model_cls(\n",
    "            estimators=estimators,\n",
    "            categorical_features=categorical_features,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model class: {experiment.model_class}\")\n",
    "\n",
    "\n",
    "def run_experiment(experiment: FinalExperiment) -> FinalExperimentResult:\n",
    "    X_train, y_train, weights_train, X_test, y_test, weights_test, categorical_features = datasets[experiment.dataset]\n",
    "\n",
    "    model = _get_model_instance(experiment, num_features=X_train.shape[1], categorical_features=categorical_features)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    (b_precision, s_precision), (b_recall, s_recall), (b_f1_score, s_f1_score), _ = precision_recall_fscore_support(\n",
    "        y_test, y_pred, labels=[\"b\", \"s\"], average=None, zero_division=0\n",
    "    )\n",
    "    ams_score = src.evaluate.ams_score(y_true=y_test, y_pred=y_pred, weights=weights_test)\n",
    "    return FinalExperimentResult(\n",
    "        **experiment.model_dump(),\n",
    "        accuracy=accuracy,\n",
    "        b_recall=b_recall,\n",
    "        b_precision=b_precision,\n",
    "        b_f1_score=b_f1_score,\n",
    "        s_recall=s_recall,\n",
    "        s_precision=s_precision,\n",
    "        s_f1_score=s_f1_score,\n",
    "        ams_score=ams_score,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5a84bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set, TypeVar, Type\n",
    "import os\n",
    "\n",
    "T = TypeVar(\"T\", bound=Union[FinalExperimentResult, FinalExperiment])\n",
    "\n",
    "\n",
    "def store_experiment_set(experiments: Set[FinalExperimentResult] | Set[FinalExperiment], filename: str) -> None:\n",
    "    \"\"\"Store a set of FinalExperimentResult to a JSONL file.\"\"\"\n",
    "    if not os.path.exists(os.path.dirname(filename)):\n",
    "        os.makedirs(os.path.dirname(filename))\n",
    "    with open(filename, \"w\") as f:\n",
    "        for er in experiments:\n",
    "            if not isinstance(er, (FinalExperimentResult, FinalExperiment)):\n",
    "                raise ValueError(f\"Invalid type in experiments set: {type(er)}\")\n",
    "            f.write(er.model_dump_json() + \"\\n\")\n",
    "\n",
    "\n",
    "def load_experiment_set(cls: Type[T], filename: str) -> Set[T]:\n",
    "    \"\"\"Load a set of ExperimentResult from a JSONL file.\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        return set()\n",
    "    experiments: Set[T] = set()\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            experiments.add(cls.model_validate_json(line.strip()))\n",
    "    return experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77370d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set, Tuple\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def run_all_experiments(\n",
    "    experiments: Set[FinalExperiment], *, verbose: bool = True, results_directory: Optional[os.PathLike] = None\n",
    ") -> Tuple[Set[FinalExperimentResult], Set[FinalExperiment]]:\n",
    "    if results_directory is None:\n",
    "        results: Set[FinalExperimentResult] = set()\n",
    "        failed: Set[FinalExperiment] = set()\n",
    "    else:\n",
    "        results: Set[FinalExperimentResult] = load_experiment_set(\n",
    "            FinalExperimentResult, os.path.join(results_directory, \"final-experiments-results.jsonl\")\n",
    "        )\n",
    "        failed: Set[FinalExperiment] = load_experiment_set(\n",
    "            FinalExperiment, os.path.join(results_directory, \"final-experiments-failed.jsonl\")\n",
    "        )\n",
    "    missing_experiments = experiments - results\n",
    "    # store_experiment_set( # For debugging only\n",
    "    #     missing_experiments,\n",
    "    #     os.path.join(results_directory, \"experiments-missing.jsonl\"),\n",
    "    # )\n",
    "    bar = tqdm(total=len(missing_experiments), desc=\"Running experiments\", disable=not verbose)\n",
    "    try:\n",
    "        for experiment in missing_experiments:\n",
    "            # Skip experiments that have already been run\n",
    "            if experiment in results:\n",
    "                bar.update(1)\n",
    "                continue\n",
    "            bar.set_postfix_str(\n",
    "                f\"{experiment.model_class} with {experiment.continuous_estimator_class} on {experiment.dataset}\"\n",
    "            )\n",
    "            bar.refresh()\n",
    "            try:\n",
    "                results.add(run_experiment(experiment))\n",
    "            except Exception as e:\n",
    "                warnings.warn(f\"Experiment failed: {e}\")\n",
    "                failed.add(experiment)\n",
    "            bar.update(1)\n",
    "            if results_directory is not None:\n",
    "                # Save intermediate results\n",
    "                store_experiment_set(\n",
    "                    results,\n",
    "                    os.path.join(results_directory, \"final-experiments-results.jsonl\"),\n",
    "                )\n",
    "                store_experiment_set(\n",
    "                    failed,\n",
    "                    os.path.join(results_directory, \"final-experiments-failed.jsonl\"),\n",
    "                )\n",
    "    finally:\n",
    "        bar.close()\n",
    "    return results, failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de408a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:  19%|█▉        | 4/21 [05:01<33:11, 117.14s/it, CategoricalAwareBespokeNB with RobustGaussianEstimator on original]             c:\\Users\\mirxm\\Storage\\Work\\MDS\\S3\\AML\\HiggsBosonATLAS\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\mirxm\\Storage\\Work\\MDS\\S3\\AML\\HiggsBosonATLAS\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:222: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "Running experiments:  90%|█████████ | 19/21 [08:37<00:08,  4.24s/it, CategoricalAwareBespokeNB with RobustEagerGaussianKDEstimator on original]c:\\Users\\mirxm\\Storage\\Work\\MDS\\S3\\AML\\HiggsBosonATLAS\\src\\naive_bayes\\kde_estimators\\__init__.py:256: UserWarning: All data points are NaN. Density estimation cannot be computed. Using empty density.\n",
      "  warnings.warn(\"All data points are NaN. Density estimation cannot be computed. Using empty density.\")\n",
      "Running experiments: 100%|██████████| 21/21 [39:20<00:00, 112.38s/it, BespokeNB with EagerGaussianKDEstimator on drop-columns]                  \n"
     ]
    }
   ],
   "source": [
    "final_experiments = load_experiment_set(FinalExperiment, \"../results/final-experiments.jsonl\")\n",
    "np.seterr(divide=\"ignore\", invalid=\"ignore\")\n",
    "with warnings.catch_warnings():\n",
    "    run_all_experiments(experiments=set(final_experiments), results_directory=\"../results/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba63ba",
   "metadata": {},
   "source": [
    "For the report, let us print all the results in a $\\LaTeX$ table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "decf4b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaTeX table lines for final experiment results:\n",
      "Gaussian NB  (Drop Missing Rows)& 0.43 & - & 0.74 & 0.74 \\\\\n",
      "Gaussian NB  (Drop Missing Columns)& 0.61 & - & 0.72 & 0.68 \\\\\n",
      "Histogram NB  (Drop Missing Rows)& 0.54 & - & 0.74 & 0.72 \\\\\n",
      "Histogram NB  (Drop Missing Columns)& 0.72 & - & 0.67 & 0.67 \\\\\n",
      "Eager Gaussian KDE NB  (Drop Missing Rows)& 0.50 & - & 0.79 & 0.79 \\\\\n",
      "Eager Gaussian KDE NB  (Drop Missing Columns)& 0.75 & - & 0.74 & 0.71 \\\\\n",
      "Yeo-Johnson Gaussian NB  (Drop Missing Rows)& 0.25 & - & 0.58 & 0.46 \\\\\n",
      "Yeo-Johnson Gaussian NB  (Drop Missing Columns)& 0.03 & - & 0.66 & 0.40 \\\\\n",
      "Robust Gaussian NB & 0.60 & - & 0.74 & 0.68 \\\\\n",
      "Robust Histogram NB & 0.76 & - & 0.72 & 0.71 \\\\\n",
      "Robust Eager Gaussian KDE NB & 0.60 & - & 0.72 & 0.69 \\\\\n",
      "Robust Yeo-Johnson Gaussian NB & 0.20 & - & 0.67 & 0.43 \\\\\n",
      "Robust Gaussian NB with Categorical Dependency& 0.59 & - & 0.74 & 0.69 \\\\\n",
      "Robust Histogram NB with Categorical Dependency& 0.68 & - & 0.74 & 0.72 \\\\\n",
      "Robust Eager Gaussian KDE NB with Categorical Dependency& 0.86 & - & 0.79 & 0.77 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirxm\\AppData\\Local\\Temp\\ipykernel_42848\\2579190765.py:35: UserWarning: No results for Gaussian NB with \n",
      "  warnings.warn(f\"No results for {estimator_name} NB with {model_name}\")\n",
      "C:\\Users\\mirxm\\AppData\\Local\\Temp\\ipykernel_42848\\2579190765.py:35: UserWarning: No results for Histogram NB with \n",
      "  warnings.warn(f\"No results for {estimator_name} NB with {model_name}\")\n",
      "C:\\Users\\mirxm\\AppData\\Local\\Temp\\ipykernel_42848\\2579190765.py:35: UserWarning: No results for Eager Gaussian KDE NB with \n",
      "  warnings.warn(f\"No results for {estimator_name} NB with {model_name}\")\n",
      "C:\\Users\\mirxm\\AppData\\Local\\Temp\\ipykernel_42848\\2579190765.py:35: UserWarning: No results for Yeo-Johnson Gaussian NB with \n",
      "  warnings.warn(f\"No results for {estimator_name} NB with {model_name}\")\n",
      "C:\\Users\\mirxm\\AppData\\Local\\Temp\\ipykernel_42848\\2579190765.py:35: UserWarning: No results for Gaussian NB with with Categorical Dependency\n",
      "  warnings.warn(f\"No results for {estimator_name} NB with {model_name}\")\n",
      "C:\\Users\\mirxm\\AppData\\Local\\Temp\\ipykernel_42848\\2579190765.py:35: UserWarning: No results for Histogram NB with with Categorical Dependency\n",
      "  warnings.warn(f\"No results for {estimator_name} NB with {model_name}\")\n",
      "C:\\Users\\mirxm\\AppData\\Local\\Temp\\ipykernel_42848\\2579190765.py:35: UserWarning: No results for Eager Gaussian KDE NB with with Categorical Dependency\n",
      "  warnings.warn(f\"No results for {estimator_name} NB with {model_name}\")\n",
      "C:\\Users\\mirxm\\AppData\\Local\\Temp\\ipykernel_42848\\2579190765.py:35: UserWarning: No results for Yeo-Johnson Gaussian NB with with Categorical Dependency\n",
      "  warnings.warn(f\"No results for {estimator_name} NB with {model_name}\")\n",
      "C:\\Users\\mirxm\\AppData\\Local\\Temp\\ipykernel_42848\\2579190765.py:35: UserWarning: No results for Robust Yeo-Johnson Gaussian NB with with Categorical Dependency\n",
      "  warnings.warn(f\"No results for {estimator_name} NB with {model_name}\")\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "final_experiment_results = load_experiment_set(FinalExperimentResult, \"../results/final-experiments-results.jsonl\")\n",
    "final_experiment_results = pd.DataFrame([er.model_dump() for er in final_experiment_results])\n",
    "\n",
    "final_latex_table_lines = []\n",
    "for model_class, model_name in [\n",
    "    (\"BespokeNB\", \"\"),\n",
    "    (\"CategoricalAwareBespokeNB\", \"with Categorical Dependency\"),\n",
    "]:\n",
    "    for continuous_estimator_class, estimator_name in [\n",
    "        (\"GaussianEstimator\", \"Gaussian\"),\n",
    "        (\"HistogramEstimator\", \"Histogram\"),\n",
    "        (\"EagerGaussianKDEstimator\", \"Eager Gaussian KDE\"),\n",
    "        (\"YeoJohnsonGaussianEstimator\", \"Yeo-Johnson Gaussian\"),\n",
    "        (\"RobustGaussianEstimator\", \"Robust Gaussian\"),\n",
    "        (\"RobustHistogramEstimator\", \"Robust Histogram\"),\n",
    "        (\"RobustEagerGaussianKDEstimator\", \"Robust Eager Gaussian KDE\"),\n",
    "        (\"RobustYeoJohnsonGaussianEstimator\", \"Robust Yeo-Johnson Gaussian\"),\n",
    "    ]:\n",
    "        for dataset, dataset_name in [\n",
    "            (\"original\", \"\"),\n",
    "            (\"drop-rows\", \" (Drop Missing Rows)\"),\n",
    "            (\"drop-columns\", \" (Drop Missing Columns)\"),\n",
    "        ]:\n",
    "            if \"Robust\" in continuous_estimator_class and dataset != \"original\":\n",
    "                # Ignore these results, as they make little sense\n",
    "                continue\n",
    "            subset = final_experiment_results[\n",
    "                (final_experiment_results[\"model_class\"] == model_class)\n",
    "                & (final_experiment_results[\"continuous_estimator_class\"] == continuous_estimator_class)\n",
    "                & (final_experiment_results[\"dataset\"] == dataset)\n",
    "            ]\n",
    "            if subset.empty:\n",
    "                warnings.warn(f\"No results for {estimator_name} NB with {model_name}\")\n",
    "                continue\n",
    "            best = subset[\"ams_score\"].max()\n",
    "            best_subset = subset[subset[\"ams_score\"] == best]\n",
    "            for j, exp in best_subset.iterrows():\n",
    "                macro_f1 = (exp[\"b_f1_score\"] + exp[\"s_f1_score\"]) / 2\n",
    "                final_latex_table_lines.append(\n",
    "                    f\"{estimator_name} NB {model_name}{dataset_name}& \"\n",
    "                    f\"{exp['ams_score']:.2f} & \"\n",
    "                    \"- & \"\n",
    "                    f\"{exp['accuracy']:.2f} & \"\n",
    "                    f\"{macro_f1:.2f} \\\\\\\\\"\n",
    "                )\n",
    "\n",
    "print(\"LaTeX table lines for final experiment results:\")\n",
    "for line in final_latex_table_lines:\n",
    "    print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "higgsbosonatlas (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
